{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Documentation\n",
    "====================\n",
    "\n",
    "This code is for time series forecasting using LSTM (Long Short Term Memory) networks with TensorFlow and Keras. It uses the 'jena\\_climate\\_2009\\_2016.csv' dataset which contains weather data collected in Jena, Germany.\n",
    "\n",
    "Importing Libraries and Loading Data\n",
    "-----------------------------------\n",
    "\n",
    "The required libraries are imported and the dataset is loaded into a pandas dataframe. The first few rows of the dataframe and the column names are printed.\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "df= pd.read_csv('jena_climate_2009_2016.csv')\n",
    "print(df.head())\n",
    "print(list(df.columns))\n",
    "```\n",
    "Preparing Data\n",
    "--------------\n",
    "\n",
    "The raw data is separated from the temperature column. The temperature column is plotted to visualize the data. The data is then split into training, validation, and testing sets.\n",
    "```python\n",
    "raw_data=df.iloc[:,1:]\n",
    "temperature=df.iloc[:,2]\n",
    "print(temperature.head())\n",
    "\n",
    "temperature.iloc[:1440].plot(figsize=(12,5))\n",
    "\n",
    "num_train_samples=int(0.5*len(temperature))\n",
    "num_val_samples=int(0.25*len(temperature))\n",
    "num_test_samples=len(temperature)-num_train_samples-num_val_samples\n",
    "print(f'number of train samoles :{num_train_samples}  \\nnumber of test samples :{num_test_samples} \\nnumber of valedation data :{num_val_samples}  ')\n",
    "```\n",
    "The raw data is then normalized by subtracting the mean and dividing by the standard deviation.\n",
    "```python\n",
    "mean=raw_data[:num_train_samples].mean(axis=0)\n",
    "raw_data-=mean\n",
    "std=raw_data[:num_train_samples].std(axis=0)\n",
    "raw_data/=std\n",
    "raw_data.iloc[:1440].plot(figsize=(120,5))\n",
    "```\n",
    "Creating Datasets\n",
    "-----------------\n",
    "\n",
    "The training, validation, and testing datasets are created using the `timeseries_dataset_from_array` function from Keras.\n",
    "```python\n",
    "sampling_rate=6\n",
    "sequence_length=120\n",
    "delay=sampling_rate*(sequence_lenght+24-1)\n",
    "batch_size=256\n",
    "\n",
    "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=0,\n",
    "    end_index=num_train_samples)\n",
    "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples,\n",
    "    end_index=num_train_samples + num_val_samples)\n",
    "\n",
    "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples + num_val_samples)\n",
    "```\n",
    "The shape of the samples and targets in the training dataset is printed.\n",
    "```python\n",
    "for samples, targets in train_dataset:\n",
    "    print(\"samples shape:\", samples.shape)\n",
    "    print(\"targets shape:\", targets.shape)\n",
    "    break\n",
    "```\n",
    "Building and Training the Model\n",
    "-------------------------------\n",
    "\n",
    "The first LSTM model is created with 16 LSTM cells and a dense layer with 1 unit. The model is compiled with the RMSprop optimizer and the mean squared error loss function. The model is trained on the training dataset for 10 epochs and the validation data is used for validation.\n",
    "```python\n",
    "inputs=keras.Input(shape=(sequence_length,raw_data.shape[-1]))\n",
    "x=keras.layers.LSTM(16)(inputs)\n",
    "outputs=keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,\n",
    "                    validation_data=val_dataset)\n",
    "```\n",
    "The training and validation mean absolute error (MAE) are plotted.\n",
    "```python\n",
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "A second LSTM model is created with 32 LSTM cells, recurrent dropout, and a dense layer with 1 unit. The model is compiled with the RMSprop optimizer and the mean squared error loss function. The model is trained on the training dataset for 10 epochs.\n",
    "```python\n",
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = keras.layers.LSTM(32, recurrent_dropout=0.25)(inputs)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,)\n",
    "```\n",
    "The training and validation mean absolute error (MAE) are plotted.\n",
    "```python\n",
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "df= pd.read_csv('jena_climate_2009_2016.csv')\n",
    "print(df.head())\n",
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data=df.iloc[:,1:]\n",
    "temperature=df.iloc[:,2]\n",
    "print(temperature.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature.iloc[:1440].plot(figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparating teat train data\n",
    "num_train_samples=int(0.5*len(temperature))\n",
    "num_val_samples=int(0.25*len(temperature))\n",
    "num_test_samples=len(temperature)-num_train_samples-num_val_samples\n",
    "print(f'number of train samoles :{num_train_samples}  \\nnumber of test samples :{num_test_samples} \\nnumber of valedation data :{num_val_samples}  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=raw_data[:num_train_samples].mean(axis=0)\n",
    "raw_data-=mean\n",
    "std=raw_data[:num_train_samples].std(axis=0)\n",
    "raw_data/=std\n",
    "raw_data.iloc[:1440].plot(figsize=(120,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate=6\n",
    "sequence_length=120\n",
    "delay=sampling_rate*(sequence_lenght+24-1)\n",
    "batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=0,\n",
    "    end_index=num_train_samples)\n",
    "val_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples,\n",
    "    end_index=num_train_samples + num_val_samples)\n",
    "\n",
    "test_dataset = keras.utils.timeseries_dataset_from_array(\n",
    "    raw_data[:-delay],\n",
    "    targets=temperature[delay:],\n",
    "    sampling_rate=sampling_rate,\n",
    "    sequence_length=sequence_length,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    start_index=num_train_samples + num_val_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for samples, targets in train_dataset:\n",
    "    print(\"samples shape:\", samples.shape)\n",
    "    print(\"targets shape:\", targets.shape)\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=keras.Input(shape=(sequence_length,raw_data.shape[-1]))\n",
    "x=keras.layers.LSTM(16)(inputs)\n",
    "outputs=keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,\n",
    "                    validation_data=val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "x = keras.layers.LSTM(32, recurrent_dropout=0.25)(inputs)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "outputs = keras.layers.Dense(1)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\", metrics=[\"mae\"])\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=10,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history[\"mae\"]\n",
    "val_loss = history.history[\"val_mae\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"Training MAE\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"Validation MAE\")\n",
    "plt.title(\"Training and validation MAE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2fb167dcecf7a85c21ab7619f4c674d1bc2519ce8a43f1e92a276adba5a6a17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
