{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire Detection and Classification\n",
    "\n",
    "This Jupyter notebook demonstrates the process of building and training a K-Nearest Neighbors (KNN) classifier and a neural network for fire detection and classification using a custom dataset. The dataset consists of images of fires and non-fires.\n",
    "dataset is avialable at :https://www.kaggle.com/datasets/phylake1337/fire-dataset/data\n",
    "## Table of Contents\n",
    "1. [Imports and Setup](#imports-and-setup)\n",
    "2. [Data Loading and Preprocessing](#data-loading-and-preprocessing)\n",
    "3. [K-Nearest Neighbors Classifier](#k-nearest-neighbors-classifier)\n",
    "4. [Neural Network Model](#neural-network-model)\n",
    "\n",
    "## Imports and Setup\n",
    "\n",
    "We start by importing the necessary libraries and modules.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from joblib import dump\n",
    "from tensorflow.keras import models, layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "```\n",
    "\n",
    "## Data Loading and Preprocessing\n",
    "\n",
    "The dataset is loaded and preprocessed using OpenCV. The images are resized to 32x32 pixels, normalized, and flattened to a 1D array. The feature vectors and labels are stored in separate lists.\n",
    "\n",
    "```python\n",
    "feature_vectors = []\n",
    "all_labels = []\n",
    "\n",
    "for i, address in enumerate(glob.glob(\"fire_dataset\\\\*\\\\*\")):\n",
    "    img = cv2.imread(address)\n",
    "    img = cv2.resize(img, (32, 32))\n",
    "    img = img / 255.0\n",
    "    img = img.flatten()\n",
    "    feature_vectors.append(img)\n",
    "    label = address.split(\"\\\\\")[1]\n",
    "    all_labels.append(label)\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(f\"[INFO] {i} images processed\")\n",
    "```\n",
    "\n",
    "## K-Nearest Neighbors Classifier\n",
    "\n",
    "A K-Nearest Neighbors classifier is trained on the dataset and evaluated for accuracy. The trained classifier is then saved to a file.\n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_vectors, all_labels, train_size=0.8)\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy is: {:.2f}%'.format(accuracy * 100))\n",
    "\n",
    "dump(clf, 'fire_knn_cls.joblib')\n",
    "```\n",
    "\n",
    "## Neural Network Model\n",
    "\n",
    "The labels are encoded and converted to one-hot encoding for use in a neural network. A simple neural network model is created using TensorFlow's Sequential API. The model consists of an input layer, two hidden layers with ReLU activation functions, and an output layer with a softmax activation function.\n",
    "\n",
    "```python\n",
    "le = LabelEncoder()\n",
    "encoded_labels = le.fit_transform(all_labels)\n",
    "one_hot_labels = to_categorical(encoded_labels)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature_vectors, one_hot_labels, test_size=0.2)\n",
    "\n",
    "net = models.Sequential([\n",
    "    layers.Dense(300, activation='relu', input_dim=3072),\n",
    "    layers.Dense(40, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "print(net.summary())\n",
    "\n",
    "net.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "H = net.fit(x_train, y_train, batch_size=16, validation_data=(x_test, y_test), epochs=1)\n",
    "```\n",
    "\n",
    "The model is compiled with the SGD optimizer and categorical cross-entropy loss function. The model is then trained for 1 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from joblib import dump\n",
    "from tensorflow.keras import models, layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Initialize lists to hold feature vectors and labels\n",
    "feature_vectors = []\n",
    "all_labels = []\n",
    "\n",
    "# Read and process images from the dataset\n",
    "for i, address in enumerate(glob.glob(\"fire_dataset\\\\*\\\\*\")):\n",
    "    img = cv2.imread(address)  # Read the image\n",
    "    img = cv2.resize(img, (32, 32))  # Resize the image to 32x32 pixels\n",
    "    img = img / 255.0  # Normalize the image\n",
    "    img = img.flatten()  # Flatten the image to a 1D array\n",
    "    feature_vectors.append(img)  # Append the feature vector\n",
    "    label = address.split(\"\\\\\")[1]  # Extract the label from the file path\n",
    "    all_labels.append(label)  # Append the label\n",
    "\n",
    "    # Print progress every 100 images\n",
    "    if i % 100 == 0:\n",
    "        print(f\"[INFO] {i} images processed\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_vectors, all_labels, train_size=0.8)\n",
    "\n",
    "# Train a K-Nearest Neighbors classifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print('Accuracy is: {:.2f}%'.format(accuracy * 100))\n",
    "\n",
    "# Save the trained classifier\n",
    "dump(clf, 'fire_knn_cls.joblib')\n",
    "\n",
    "# Encode the labels\n",
    "le = LabelEncoder()\n",
    "encoded_labels = le.fit_transform(all_labels)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "one_hot_labels = to_categorical(encoded_labels)\n",
    "\n",
    "# Split the data into training and testing sets for the neural network\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature_vectors, one_hot_labels, test_size=0.2)\n",
    "\n",
    "# Create a neural network model\n",
    "net = models.Sequential([\n",
    "    layers.Dense(300, activation='relu', input_dim=3072),\n",
    "    layers.Dense(40, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "print(net.summary())\n",
    "\n",
    "# Compile the neural network model\n",
    "net.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the neural network model\n",
    "H = net.fit(x_train, y_train, batch_size=16, validation_data=(x_test, y_test), epochs=1)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
